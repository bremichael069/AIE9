{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Agentic RAG From Scratch: Building with LangGraph and Open-Source Models\n",
    "\n",
    "In this notebook, we'll look under the hood of `create_agent` and build an agentic RAG application **from scratch** using LangGraph's low-level primitives and locally-hosted open-source models.\n",
    "\n",
    "**Learning Objectives:**\n",
    "- Understand LangGraph's core constructs: StateGraph, nodes, edges, and conditional routing\n",
    "- Build a ReAct agent from scratch without high-level abstractions\n",
    "- Use Ollama to run open-source models locally (gpt-oss:20b + embeddinggemma)\n",
    "- Transition from `aimakerspace` utilities to the LangChain ecosystem\n",
    "\n",
    "## Table of Contents:\n",
    "\n",
    "- **Breakout Room #1:** LangGraph Fundamentals & Building Agents from Scratch\n",
    "  - Task 1: Dependencies & Ollama Setup\n",
    "  - Task 2: LangGraph Core Concepts (StateGraph, Nodes, Edges)\n",
    "  - Task 3: Building a ReAct Agent from Scratch\n",
    "  - Task 4: Adding Tools to Your Agent\n",
    "  - Question #1 & Question #2\n",
    "  - Activity #1: Implement a Custom Routing Function\n",
    "\n",
    "- **Breakout Room #2:** Agentic RAG with Local Models\n",
    "  - Task 5: Loading & Chunking with LangChain\n",
    "  - Task 6: Setting up Qdrant with Local Embeddings\n",
    "  - Task 7: Creating a RAG Tool\n",
    "  - Task 8: Building Agentic RAG from Scratch\n",
    "  - Question #3 & Question #4\n",
    "  - Activity #2: Extend the Agent with Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "---\n",
    "# Breakout Room #1\n",
    "## LangGraph Fundamentals & Building Agents from Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## Task 1: Dependencies & Ollama Setup\n",
    "\n",
    "Before we begin, make sure you have:\n",
    "\n",
    "1. **Ollama installed** - Download from [ollama.com](https://ollama.com/)\n",
    "2. **Ollama running** - Start with `ollama serve` in a terminal\n",
    "3. **Models pulled** - Run these commands:\n",
    "\n",
    "```bash\n",
    "# Chat model for reasoning and generation (~12GB)\n",
    "ollama pull gpt-oss:20b\n",
    "\n",
    "# Embedding model for RAG (~622MB)\n",
    "ollama pull embeddinggemma\n",
    "```\n",
    "\n",
    "> **Note**: If you don't have enough RAM/VRAM for `gpt-oss:20b` (requires 16GB+ VRAM or 24GB+ RAM), you can substitute with `llama3.2:3b` or another smaller model.\n",
    "\n",
    "**ðŸ“š Documentation:**\n",
    "- [Ollama Installation Guide](https://ollama.com/download)\n",
    "- [gpt-oss Model Card](https://ollama.com/library/gpt-oss)\n",
    "- [EmbeddingGemma Model Card](https://ollama.com/library/embeddinggemma)\n",
    "- [langchain-ollama Integration](https://python.langchain.com/docs/integrations/providers/ollama/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core imports we'll use throughout the notebook\n",
    "import os\n",
    "import getpass\n",
    "import json\n",
    "from uuid import uuid4\n",
    "from typing import Annotated, TypedDict, Literal\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()  # Required for async operations in Jupyter\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"2\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"2\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"2\"\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"2\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9004319",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install langchain-ollama ollama\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat Model Test: Ollama is working!\n",
      "Embedding Model Test: Vector dimension = 768\n",
      "\n",
      "Ollama is ready!\n"
     ]
    }
   ],
   "source": [
    "# Verify Ollama is running and models are available\n",
    "from langchain_ollama import ChatOllama, OllamaEmbeddings\n",
    "\n",
    "# Test connection to Ollama\n",
    "try:\n",
    "    test_llm = ChatOllama(model=\"gpt-oss:20b\", temperature=0)\n",
    "    test_response = test_llm.invoke(\"Say 'Ollama is working!' in exactly 3 words.\")\n",
    "    print(f\"Chat Model Test: {test_response.content}\")\n",
    "    \n",
    "    test_embeddings = OllamaEmbeddings(model=\"embeddinggemma\")\n",
    "    test_vector = test_embeddings.embed_query(\"test\")\n",
    "    print(f\"Embedding Model Test: Vector dimension = {len(test_vector)}\")\n",
    "    print(\"\\nOllama is ready!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error connecting to Ollama: {e}\")\n",
    "    print(\"\\nMake sure:\")\n",
    "    print(\"1. Ollama is installed: https://ollama.com/\")\n",
    "    print(\"2. Ollama is running: 'ollama serve'\")\n",
    "    print(\"3. Models are pulled: 'ollama pull gpt-oss:20b' and 'ollama pull embeddinggemma'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## Task 2: LangGraph Core Concepts\n",
    "\n",
    "In Session 3, we used `create_agent` which abstracts away the complexity. Now let's understand what's happening under the hood!\n",
    "\n",
    "### LangGraph models workflows as **graphs** with three key components:\n",
    "\n",
    "### 1. State\n",
    "A shared data structure that represents the current snapshot of your application:\n",
    "\n",
    "```python\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]  # Conversation history\n",
    "```\n",
    "\n",
    "The `add_messages` **reducer** ensures new messages are appended (not replaced) when the state updates.\n",
    "\n",
    "### 2. Nodes\n",
    "Python functions that encode the logic of your agent:\n",
    "- Receive the current state\n",
    "- Perform computation or side-effects\n",
    "- Return an updated state\n",
    "\n",
    "### 3. Edges\n",
    "Functions that determine which node to execute next:\n",
    "- **Normal edges**: Always go to a specific node\n",
    "- **Conditional edges**: Choose the next node based on state\n",
    "\n",
    "**ðŸ“š Documentation:**\n",
    "- [LangGraph Low-Level Concepts](https://langchain-ai.github.io/langgraph/concepts/low_level/)\n",
    "- [LangGraph Quickstart](https://langchain-ai.github.io/langgraph/tutorials/introduction/)\n",
    "- [StateGraph API Reference](https://langchain-ai.github.io/langgraph/reference/graphs/#langgraph.graph.StateGraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple echo graph created!\n"
     ]
    }
   ],
   "source": [
    "# Let's build our first LangGraph workflow - a simple echo graph\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "# Step 1: Define the State\n",
    "class SimpleState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "# Step 2: Define Nodes (functions that process state)\n",
    "def echo_node(state: SimpleState):\n",
    "    \"\"\"A simple node that echoes the last message.\"\"\"\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    echo_response = AIMessage(content=f\"You said: {last_message.content}\")\n",
    "    return {\"messages\": [echo_response]}\n",
    "\n",
    "# Step 3: Build the Graph\n",
    "echo_graph = StateGraph(SimpleState)\n",
    "\n",
    "# Add nodes\n",
    "echo_graph.add_node(\"echo\", echo_node)\n",
    "\n",
    "# Add edges (START -> echo -> END)\n",
    "echo_graph.add_edge(START, \"echo\")\n",
    "echo_graph.add_edge(\"echo\", END)\n",
    "\n",
    "# Compile the graph\n",
    "echo_app = echo_graph.compile()\n",
    "\n",
    "print(\"Simple echo graph created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the graph structure\n",
    "try:\n",
    "    from IPython.display import display, Image\n",
    "    display(Image(echo_app.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(f\"Could not display graph image: {e}\")\n",
    "    print(\"\\nGraph structure (ASCII):\")\n",
    "    print(echo_app.get_graph().draw_ascii())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell-11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversation:\n",
      "  [Human]: Hello, LangGraph!\n",
      "  [AI]: You said: Hello, LangGraph!\n"
     ]
    }
   ],
   "source": [
    "# Test the echo graph\n",
    "result = echo_app.invoke({\"messages\": [HumanMessage(content=\"Hello, LangGraph!\")]})\n",
    "\n",
    "print(\"Conversation:\")\n",
    "for msg in result[\"messages\"]:\n",
    "    role = \"Human\" if isinstance(msg, HumanMessage) else \"AI\"\n",
    "    print(f\"  [{role}]: {msg.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## Task 3: Building a ReAct Agent from Scratch\n",
    "\n",
    "Now let's build something more sophisticated: a **ReAct agent** that can:\n",
    "1. **Reason** about what to do\n",
    "2. **Act** by calling tools\n",
    "3. **Observe** results\n",
    "4. **Repeat** until done\n",
    "\n",
    "This is exactly what `create_agent` does under the hood. Let's build it ourselves!\n",
    "\n",
    "### The Agent Loop Architecture\n",
    "\n",
    "```\n",
    "                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                    â”‚    START     â”‚\n",
    "                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                           â”‚\n",
    "                           â–¼\n",
    "                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "             â”Œâ”€â”€â”€â”€â”€â–ºâ”‚    agent     â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "             â”‚      â”‚  (call LLM)  â”‚         â”‚\n",
    "             â”‚      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚\n",
    "             â”‚             â”‚                 â”‚\n",
    "             â”‚             â–¼                 â”‚\n",
    "             â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚\n",
    "             â”‚      â”‚ should_      â”‚         â”‚\n",
    "             â”‚      â”‚ continue?    â”‚         â”‚\n",
    "             â”‚      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚\n",
    "             â”‚             â”‚                 â”‚\n",
    "             â”‚    tool_calls?                â”‚\n",
    "             â”‚     â”‚           â”‚             â”‚\n",
    "             â”‚    YES         NO             â”‚\n",
    "             â”‚     â”‚           â”‚             â”‚\n",
    "             â”‚     â–¼           â–¼             â”‚\n",
    "             â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”         â”‚\n",
    "             â”‚ â”‚ tools  â”‚  â”‚  END  â”‚         â”‚\n",
    "             â””â”€â”¤(executeâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚\n",
    "               â”‚ tools) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "               â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "**ðŸ“š Documentation:**\n",
    "- [How to create a ReAct agent from scratch](https://langchain-ai.github.io/langgraph/how-tos/react-agent-from-scratch/)\n",
    "- [ReAct Agent Conceptual Guide](https://langchain-ai.github.io/langgraph/concepts/agentic_concepts/#react-agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cell-13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AgentState defined with messages field\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import BaseMessage, SystemMessage, ToolMessage\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "# Step 1: Define the Agent State\n",
    "class AgentState(TypedDict):\n",
    "    \"\"\"The state of our agent - just a list of messages.\"\"\"\n",
    "    messages: Annotated[list[BaseMessage], add_messages]\n",
    "\n",
    "print(\"AgentState defined with messages field\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cell-14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM initialized: gpt-oss:20b\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Initialize our local LLM with Ollama\n",
    "llm = ChatOllama(\n",
    "    model=\"gpt-oss:20b\",\n",
    "    temperature=0,  # Deterministic for reproducibility\n",
    ")\n",
    "\n",
    "print(f\"LLM initialized: {llm.model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## Task 4: Adding Tools to Your Agent\n",
    "\n",
    "Tools are functions that the agent can call. We use the `@tool` decorator and **bind** them to the LLM.\n",
    "\n",
    "**ðŸ“š Documentation:**\n",
    "- [LangChain Tools Conceptual Guide](https://python.langchain.com/docs/concepts/tools/)\n",
    "- [@tool Decorator Reference](https://python.langchain.com/api_reference/core/tools/langchain_core.tools.convert.tool.html)\n",
    "- [ToolNode Prebuilt](https://langchain-ai.github.io/langgraph/reference/prebuilt/#langgraph.prebuilt.tool_node.ToolNode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cell-16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tools defined and bound to LLM:\n",
      "  - calculate: Evaluate a mathematical expression. Use this for a...\n",
      "  - get_current_time: Get the current date and time. Use this when the u...\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Define Tools\n",
    "@tool\n",
    "def calculate(expression: str) -> str:\n",
    "    \"\"\"Evaluate a mathematical expression. Use this for any math calculations.\n",
    "    \n",
    "    Args:\n",
    "        expression: A mathematical expression to evaluate (e.g., '2 + 2', '10 * 5')\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Using eval with restricted globals for safety\n",
    "        result = eval(expression, {\"__builtins__\": {}}, {})\n",
    "        return f\"The result of {expression} is {result}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error evaluating expression: {e}\"\n",
    "\n",
    "@tool\n",
    "def get_current_time() -> str:\n",
    "    \"\"\"Get the current date and time. Use this when the user asks about the current time or date.\"\"\"\n",
    "    from datetime import datetime\n",
    "    return f\"The current date and time is: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"\n",
    "\n",
    "# Create our tool list\n",
    "tools = [calculate, get_current_time]\n",
    "\n",
    "# Bind tools to the LLM - this tells the LLM about available tools\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "print(\"Tools defined and bound to LLM:\")\n",
    "for t in tools:\n",
    "    print(f\"  - {t.name}: {t.description[:50]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent node defined\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cell-18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool node created using ToolNode prebuilt\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Define the Tool Node (executes tools)\n",
    "# We can use LangGraph's prebuilt ToolNode for convenience\n",
    "tool_node = ToolNode(tools)\n",
    "\n",
    "print(\"Tool node created using ToolNode prebuilt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cell-19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conditional routing function defined\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Define the Conditional Edge (routing logic)\n",
    "def should_continue(state: AgentState) -> Literal[\"tools\", \"end\"]:\n",
    "    \"\"\"Determine whether to call tools or end the conversation.\"\"\"\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    \n",
    "    # If the LLM made tool calls, route to tools node\n",
    "    if hasattr(last_message, 'tool_calls') and last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    \n",
    "    # Otherwise, end the conversation\n",
    "    return \"end\"\n",
    "\n",
    "print(\"Conditional routing function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cell-20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReAct agent built from scratch!\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Build the Graph!\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Add nodes\n",
    "workflow.add_node(\"agent\", agent_node)\n",
    "workflow.add_node(\"tools\", tool_node)\n",
    "\n",
    "# Set the entry point\n",
    "workflow.add_edge(START, \"agent\")\n",
    "\n",
    "# Add conditional edge from agent\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"tools\": \"tools\",  # If should_continue returns \"tools\", go to tools node\n",
    "        \"end\": END         # If should_continue returns \"end\", finish\n",
    "    }\n",
    ")\n",
    "\n",
    "# Add edge from tools back to agent (the loop!)\n",
    "workflow.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "# Compile the graph\n",
    "agent = workflow.compile()\n",
    "\n",
    "print(\"ReAct agent built from scratch!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize our agent\n",
    "try:\n",
    "    from IPython.display import display, Image\n",
    "    display(Image(agent.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(f\"Could not display graph image: {e}\")\n",
    "    print(\"\\nGraph structure (ASCII):\")\n",
    "    print(agent.get_graph().draw_ascii())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cell-22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing our from-scratch agent:\n",
      "==================================================\n",
      "\n",
      "Conversation:\n",
      "  [HumanMessage]: What is 25 * 48?\n",
      "  [AIMessage]: [Tool calls: [{'name': 'calculate', 'args': {'expression': '25 * 48'}, 'id': '68948f70-26d1-4b71-b8ac-ac231691a02f', 'type': 'tool_call'}]]\n",
      "  [ToolMessage]: The result of 25 * 48 is 1200\n",
      "  [AIMessage]: 1200\n"
     ]
    }
   ],
   "source": [
    "# Test our agent\n",
    "print(\"Testing our from-scratch agent:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "response = agent.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"What is 25 * 48?\")]\n",
    "})\n",
    "\n",
    "print(\"\\nConversation:\")\n",
    "for msg in response[\"messages\"]:\n",
    "    msg_type = type(msg).__name__\n",
    "\n",
    "    if msg.content:\n",
    "        content = msg.content\n",
    "    elif hasattr(msg, \"tool_calls\") and msg.tool_calls:\n",
    "        content = f\"[Tool calls: {msg.tool_calls}]\"\n",
    "    else:\n",
    "        content = \"[No content]\"\n",
    "\n",
    "    print(f\"  [{msg_type}]: {content[:200]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with multiple tool calls:\n",
      "==================================================\n",
      "\n",
      "Final response:\n",
      "Itâ€™s 20:40:32 (8:40â€¯PM).  \n",
      "100 divided by the current hour (20) equals **5**.\n"
     ]
    }
   ],
   "source": [
    "# Test with multiple tools\n",
    "print(\"Testing with multiple tool calls:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "response = agent.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"What time is it, and what is 100 divided by the current hour?\")]\n",
    "})\n",
    "\n",
    "print(\"\\nFinal response:\")\n",
    "print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streaming agent execution:\n",
      "==================================================\n",
      "\n",
      "[Node: agent]\n",
      "  Tool calls: ['calculate']\n",
      "\n",
      "[Node: tools]\n",
      "  Content: The result of 0.15*200 is 30.0\n",
      "\n",
      "[Node: agent]\n",
      "  Content: 30.\n"
     ]
    }
   ],
   "source": [
    "# Stream the agent's execution to see it step by step\n",
    "print(\"Streaming agent execution:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for chunk in agent.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"Calculate 15% of 200\")]},\n",
    "    stream_mode=\"updates\"\n",
    "):\n",
    "    for node_name, values in chunk.items():\n",
    "        print(f\"\\n[Node: {node_name}]\")\n",
    "        if \"messages\" in values:\n",
    "            for msg in values[\"messages\"]:\n",
    "                if hasattr(msg, 'content') and msg.content:\n",
    "                    print(f\"  Content: {msg.content[:200]}\")\n",
    "                if hasattr(msg, 'tool_calls') and msg.tool_calls:\n",
    "                    print(f\"  Tool calls: {[tc['name'] for tc in msg.tool_calls]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-25",
   "metadata": {},
   "source": [
    "---\n",
    "## â“ Question #1:\n",
    "\n",
    "In our from-scratch agent, we defined a `should_continue` function that returns either `\"tools\"` or `\"end\"`. How does this compare to how `create_agent` handles the same decision? What additional logic might `create_agent` include that we didn't implement?\n",
    "\n",
    "##### Answer:\n",
    "The should_continue function makes a simple yes/no decision: if the LLM wants a tool, continue; otherwise, stop. create_agent does the same check automatically by inspecting whether the model output is a tool call or a final answer, and it also adds extra logic like retries, validation, error handling, memory updates, and loop-safety limits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-26",
   "metadata": {},
   "source": [
    "## â“ Question #2:\n",
    "\n",
    "We used `ToolNode` from `langgraph.prebuilt` to execute tools. Looking at the tool execution flow, what would happen if we wanted to add logging, error handling, or rate limiting to tool execution? How would building our own tool node give us more control?\n",
    "\n",
    "##### Answer:\n",
    "\n",
    "\n",
    "With ToolNode from langgraph.prebuilt, tool execution is mostly a black box. You canâ€™t easily inject custom logging, retries, or rate limiting around each tool call.\n",
    "\n",
    "     - To add those, youâ€™d need to build your own tool node so you can:\n",
    "     - Log inputs, outputs, and latency\n",
    "     - Catch errors and apply retries or fallbacks\n",
    "     - Enforce rate limits and concurrency before calling tools\n",
    "A custom node gives you full control over the tool execution lifecycle instead of relying on the built-in behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-27",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸ—ï¸ Activity #1: Implement a Custom Routing Function\n",
    "\n",
    "Extend the agent by implementing a **custom routing function** that adds more sophisticated logic.\n",
    "\n",
    "Ideas:\n",
    "- Add a maximum iteration limit to prevent infinite loops\n",
    "- Route to different nodes based on the type of tool being called\n",
    "- Add a \"thinking\" step before tool execution\n",
    "\n",
    "Requirements:\n",
    "1. Modify the `should_continue` function or create a new one\n",
    "2. Add any new nodes if needed\n",
    "3. Rebuild and test the agent\n",
    "\n",
    "**ðŸ“š Documentation:**\n",
    "- [Conditional Edges](https://langchain-ai.github.io/langgraph/concepts/low_level/#conditional-edges)\n",
    "- [How to create branches for parallel node execution](https://langchain-ai.github.io/langgraph/how-tos/branching/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cell-28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReAct agent with iteration control built!\n"
     ]
    }
   ],
   "source": [
    "from typing import TypedDict, Literal\n",
    "from langchain_core.messages import BaseMessage\n",
    "from typing_extensions import Annotated\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class AgentStateWithCounter(TypedDict):\n",
    "    messages: Annotated[list[BaseMessage], add_messages]\n",
    "    iteration_count: int\n",
    "\n",
    "def custom_should_continue(state: AgentStateWithCounter) -> Literal[\"tools\", \"end\"]:\n",
    "    \"\"\"Custom routing with iteration limit.\"\"\"\n",
    "    MAX_ITER = 3\n",
    "\n",
    "    # Stop if we reached iteration limit\n",
    "    if state[\"iteration_count\"] >= MAX_ITER:\n",
    "        return \"end\"\n",
    "\n",
    "    # Get last message (this is where -1 is used)\n",
    "    last_message = state[\"messages\"][-1]\n",
    "\n",
    "    # If the last message contains tool calls, continue to tools\n",
    "    if hasattr(last_message, \"tool_calls\") and last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "\n",
    "    return \"end\"\n",
    "\n",
    "# Build your custom agent\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "# Build graph with extended state\n",
    "workflow = StateGraph(AgentStateWithCounter)\n",
    "\n",
    "# Add nodes\n",
    "workflow.add_node(\"agent\", agent_node)\n",
    "workflow.add_node(\"tools\", tool_node)\n",
    "\n",
    "# Set entry point\n",
    "workflow.add_edge(START, \"agent\")\n",
    "\n",
    "# Use your custom routing function with iteration limit\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    custom_should_continue,   # <-- your function with counter + tool check\n",
    "    {\n",
    "        \"tools\": \"tools\",\n",
    "        \"end\": END\n",
    "    }\n",
    ")\n",
    "\n",
    "# Loop back after tools\n",
    "workflow.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "# Compile\n",
    "agent = workflow.compile()\n",
    "\n",
    "print(\"ReAct agent with iteration control built!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cell-29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final messages:\n",
      "content='What is 5 + 7? Use tools.' additional_kwargs={} response_metadata={} id='4989039c-bbfb-41d7-8c01-f249bfae8408'\n",
      "content='' additional_kwargs={} response_metadata={'model': 'gpt-oss:20b', 'created_at': '2026-01-28T03:29:48.9764366Z', 'done': True, 'done_reason': 'stop', 'total_duration': 16006774900, 'load_duration': 667573100, 'prompt_eval_count': 224, 'prompt_eval_duration': 2048675900, 'eval_count': 34, 'eval_duration': 13217749800, 'logprobs': None, 'model_name': 'gpt-oss:20b', 'model_provider': 'ollama'} id='lc_run--019c02a6-350c-7a10-ac43-a85536c3239d-0' tool_calls=[{'name': 'calculate', 'args': {'expression': '5 + 7'}, 'id': '106e70ef-d342-464e-8413-20538a05d002', 'type': 'tool_call'}] invalid_tool_calls=[] usage_metadata={'input_tokens': 224, 'output_tokens': 34, 'total_tokens': 258}\n",
      "content='The result of 5 + 7 is 12' name='calculate' id='2913019e-e744-4d3e-9fbe-d4a3f7fa9444' tool_call_id='106e70ef-d342-464e-8413-20538a05d002'\n",
      "content='The result of\\u202f5\\u202f+\\u202f7\\u202fis\\u202f12.' additional_kwargs={} response_metadata={'model': 'gpt-oss:20b', 'created_at': '2026-01-28T03:30:07.2275902Z', 'done': True, 'done_reason': 'stop', 'total_duration': 18173973400, 'load_duration': 542511500, 'prompt_eval_count': 265, 'prompt_eval_duration': 3843150800, 'eval_count': 47, 'eval_duration': 13688726300, 'logprobs': None, 'model_name': 'gpt-oss:20b', 'model_provider': 'ollama'} id='lc_run--019c02a6-73f6-7fe3-abc3-5919677f332c-0' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 265, 'output_tokens': 47, 'total_tokens': 312}\n"
     ]
    }
   ],
   "source": [
    "# Test your custom agent\n",
    "initial_state = {\n",
    "    \"messages\": [(\"user\", \"What is 5 + 7? Use tools.\")],\n",
    "    \"iteration_count\": 0\n",
    "}\n",
    "\n",
    "result = agent.invoke(initial_state)\n",
    "\n",
    "print(\"Final messages:\")\n",
    "for m in result[\"messages\"]:\n",
    "    print(m)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-30",
   "metadata": {},
   "source": [
    "---\n",
    "# Breakout Room #2\n",
    "## Agentic RAG with Local Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-31",
   "metadata": {},
   "source": [
    "Now let's build a full **Agentic RAG** system from scratch using our local models!\n",
    "\n",
    "We'll transition from the `aimakerspace` utilities to the **LangChain ecosystem**:\n",
    "\n",
    "| Task | aimakerspace | LangChain |\n",
    "|------|--------------|----------|\n",
    "| Load Documents | `TextFileLoader` | `TextLoader` |\n",
    "| Split Text | `CharacterTextSplitter` | `RecursiveCharacterTextSplitter` |\n",
    "| Embeddings | Custom | `OllamaEmbeddings` |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-32",
   "metadata": {},
   "source": [
    "## Task 5: Loading & Chunking with LangChain\n",
    "\n",
    "Let's use LangChain's document loaders and text splitters.\n",
    "\n",
    "**ðŸ“š Documentation:**\n",
    "- [Document Loaders Conceptual Guide](https://python.langchain.com/docs/concepts/document_loaders/)\n",
    "- [TextLoader Reference](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.text.TextLoader.html)\n",
    "- [RecursiveCharacterTextSplitter](https://python.langchain.com/docs/how_to/recursive_text_splitter/)\n",
    "- [Text Splitters Conceptual Guide](https://python.langchain.com/docs/concepts/text_splitters/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-33",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Load the document using LangChain's TextLoader\n",
    "loader = TextLoader(\"data/HealthWellnessGuide.txt\")\n",
    "documents = loader.load()\n",
    "\n",
    "print(f\"Loaded {len(documents)} document(s)\")\n",
    "print(f\"Total characters: {sum(len(doc.page_content) for doc in documents):,}\")\n",
    "print(f\"\\nDocument metadata: {documents[0].metadata}\") \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\"data/HealthWellnessGuide.txt\", encoding=\"utf-8\")\n",
    "documents = loader.load()\n",
    "\n",
    "print(len(documents)) \"\"\"\n",
    "\n",
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\"data/HealthWellnessGuide.txt\", encoding=\"utf-8\")\n",
    "\n",
    "for doc in loader.lazy_load():\n",
    "    print(len(doc.page_content))\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-35",
   "metadata": {},
   "source": [
    "## Task 6: Setting up Qdrant with Local Embeddings\n",
    "\n",
    "Now we'll use **OllamaEmbeddings** with the `embeddinggemma` model - completely local!\n",
    "\n",
    "**ðŸ“š Documentation:**\n",
    "- [OllamaEmbeddings Reference](https://python.langchain.com/api_reference/ollama/embeddings/langchain_ollama.embeddings.OllamaEmbeddings.html)\n",
    "- [Qdrant Vector Store Integration](https://python.langchain.com/docs/integrations/vectorstores/qdrant/)\n",
    "- [Embedding Models Conceptual Guide](https://python.langchain.com/docs/concepts/embedding_models/)\n",
    "- [EmbeddingGemma Overview (Google)](https://ai.google.dev/gemma/docs/embeddinggemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding dimension: 768\n",
      "Using local model: embeddinggemma\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_qdrant import QdrantVectorStore\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import Distance, VectorParams\n",
    "\n",
    "# Initialize local embedding model\n",
    "embedding_model = OllamaEmbeddings(model=\"embeddinggemma\")\n",
    "\n",
    "# Get embedding dimension\n",
    "sample_embedding = embedding_model.embed_query(\"test\")\n",
    "embedding_dim = len(sample_embedding)\n",
    "print(f\"Embedding dimension: {embedding_dim}\")\n",
    "print(f\"Using local model: embeddinggemma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created collection: wellness_knowledge_base_local\n"
     ]
    }
   ],
   "source": [
    "# Create Qdrant client (in-memory for development)\n",
    "qdrant_client = QdrantClient(\":memory:\")\n",
    "\n",
    "# Create a collection for our wellness documents\n",
    "collection_name = \"wellness_knowledge_base_local\"\n",
    "\n",
    "qdrant_client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=VectorParams(\n",
    "        size=embedding_dim,\n",
    "        distance=Distance.COSINE\n",
    "    )\n",
    ")\n",
    "\n",
    "print(f\"Created collection: {collection_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_qdrant import QdrantVectorStore\n",
    "from qdrant_client import QdrantClient\n",
    "\n",
    "# Embeddings\n",
    "embedding_model = OllamaEmbeddings(model=\"embeddinggemma\")\n",
    "\n",
    "# Qdrant client\n",
    "qdrant_client = QdrantClient(url=\"http://localhost:6333\")\n",
    "\n",
    "collection_name = \"my_rag_collection\"\n",
    "\n",
    "# Create vector store\n",
    "vector_store = QdrantVectorStore(\n",
    "    client=qdrant_client,\n",
    "    collection_name=collection_name,\n",
    "    embedding=embedding_model\n",
    ")\n",
    "\n",
    "# Add documents\n",
    "print(\"Adding documents to vector store...\")\n",
    "vector_store.add_documents(chunks)\n",
    "print(f\"Added {len(chunks)} documents to vector store\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cell-39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved documents:\n",
      "\n",
      "--- Document 1 ---\n",
      "Chapter 3: Building a Workout Routine\n",
      "\n",
      "Starting a new exercise routine can feel overwhelming. The key is to start slowly and gradually increase intensity and duration over time....\n",
      "\n",
      "--- Document 2 ---\n",
      "Adults typically need 7-9 hours of sleep per night. Sleep occurs in cycles of about 90 minutes, alternating between REM (rapid eye movement) and non-REM sleep.\n",
      "\n",
      "The four stages of sleep:\n",
      "- Stage 1: Li...\n",
      "\n",
      "--- Document 3 ---\n",
      "- Chin Tucks: While sitting or standing tall, pull your chin back to create a \"double chin.\" Hold for 5 seconds, repeat 10 times....\n"
     ]
    }
   ],
   "source": [
    "# Test the retriever\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "test_results = retriever.invoke(\"How can I improve my sleep?\")\n",
    "\n",
    "print(\"Retrieved documents:\")\n",
    "for i, doc in enumerate(test_results, 1):\n",
    "    print(f\"\\n--- Document {i} ---\")\n",
    "    print(doc.page_content[:200] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-40",
   "metadata": {},
   "source": [
    "## Task 7: Creating a RAG Tool\n",
    "\n",
    "Now let's wrap our retriever as a tool that the agent can use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-41",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def search_wellness_knowledge(query: str) -> str:\n",
    "    \"\"\"Search the wellness knowledge base for information about health, fitness, nutrition, sleep, and mental wellness.\n",
    "    \n",
    "    Use this tool when the user asks questions about:\n",
    "    - Physical health and fitness\n",
    "    - Nutrition and diet\n",
    "    - Sleep and rest\n",
    "    - Mental health and stress management\n",
    "    - General wellness tips\n",
    "    \n",
    "    Args:\n",
    "        query: The search query to find relevant wellness information\n",
    "    \"\"\"\n",
    "    results = retriever.invoke(query)\n",
    "    \n",
    "    if not results:\n",
    "        return \"No relevant information found in the wellness knowledge base.\"\n",
    "    \n",
    "    # Format the results\n",
    "    formatted_results = []\n",
    "    for i, doc in enumerate(results, 1):\n",
    "        formatted_results.append(f\"[Source {i}]:\\n{doc.page_content}\")\n",
    "    \n",
    "    return \"\\n\\n\".join(formatted_results)\n",
    "\n",
    "print(f\"RAG tool created: {search_wellness_knowledge.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-42",
   "metadata": {},
   "source": [
    "## Task 8: Building Agentic RAG from Scratch\n",
    "\n",
    "Now let's put it all together - a complete agentic RAG system built from scratch!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define all tools for our RAG agent\n",
    "rag_tools = [search_wellness_knowledge, calculate, get_current_time]\n",
    "\n",
    "# Bind tools to the LLM\n",
    "rag_llm_with_tools = llm.bind_tools(rag_tools)\n",
    "\n",
    "print(\"Tools for RAG agent:\")\n",
    "for t in rag_tools:\n",
    "    print(f\"  - {t.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the RAG agent components\n",
    "RAG_SYSTEM_PROMPT = \"\"\"You are a helpful wellness assistant with access to a comprehensive health and wellness knowledge base.\n",
    "\n",
    "Your role is to:\n",
    "1. Answer questions about health, fitness, nutrition, sleep, and mental wellness\n",
    "2. ALWAYS search the knowledge base when the user asks wellness-related questions\n",
    "3. Provide accurate, helpful information based on the retrieved context\n",
    "4. Be supportive and encouraging in your responses\n",
    "5. If you cannot find relevant information, say so honestly\n",
    "\n",
    "Remember: Always cite information from the knowledge base when applicable.\"\"\"\n",
    "\n",
    "def rag_agent_node(state: AgentState):\n",
    "    \"\"\"The RAG agent node - calls the LLM with wellness system prompt.\"\"\"\n",
    "    messages = [SystemMessage(content=RAG_SYSTEM_PROMPT)] + state[\"messages\"]\n",
    "    response = rag_llm_with_tools.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "# Create tool node for RAG tools\n",
    "rag_tool_node = ToolNode(rag_tools)\n",
    "\n",
    "print(\"RAG agent node defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the RAG agent graph\n",
    "rag_workflow = StateGraph(AgentState)\n",
    "\n",
    "# Add nodes\n",
    "rag_workflow.add_node(\"agent\", rag_agent_node)\n",
    "rag_workflow.add_node(\"tools\", rag_tool_node)\n",
    "\n",
    "# Set entry point\n",
    "rag_workflow.add_edge(START, \"agent\")\n",
    "\n",
    "# Add conditional edge\n",
    "rag_workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    should_continue,\n",
    "    {\"tools\": \"tools\", \"end\": END}\n",
    ")\n",
    "\n",
    "# Add edge from tools back to agent\n",
    "rag_workflow.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "# Compile\n",
    "rag_agent = rag_workflow.compile()\n",
    "\n",
    "print(\"Agentic RAG built from scratch!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cell-46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the RAG agent\n",
    "try:\n",
    "    from IPython.display import display, Image\n",
    "    display(Image(rag_agent.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(f\"Could not display graph image: {e}\")\n",
    "    print(\"\\nGraph structure:\")\n",
    "    print(rag_agent.get_graph().draw_ascii())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cell-47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Agentic RAG (with local models):\n",
      "==================================================\n",
      "\n",
      "Final Response:\n",
      "==================================================\n",
      "Here are some evidenceâ€‘based, practical tips that can help you fall asleep faster, stay asleep longer, and wake up feeling refreshed.  (All of these are grounded in the wellness knowledge base we searched.)\n",
      "\n",
      "| Tip | Why it works | How to do it |\n",
      "|-----|--------------|--------------|\n",
      "| **Stick to a consistent bedtime and wakeâ€‘up time** | Your bodyâ€™s internal clock (circadian rhythm) thrives on routine.  Even on weekends, aim for the same sleep window. | Set an alarm for the same time each morning and try to go to bed 7â€“9â€¯hours before that. |\n",
      "| **Create a windâ€‘down ritual** | Reducing stimulation before bed signals your brain that itâ€™s time to sleep. | 30â€“60â€¯minutes before bed, dim the lights, read a book, do gentle stretches, or practice deepâ€‘breathing. |\n",
      "| **Keep the bedroom cool, dark, and quiet** | Low temperatures and darkness promote the release of melatonin, the hormone that regulates sleep cycles. | Aim for 60â€“67â€¯Â°F (15â€“19â€¯Â°C), use blackout curtains or a sleep mask, and consider earplugs or a whiteâ€‘noise machine. |\n",
      "| **Limit exposure to screens and bright light** | Blue light from phones, tablets, and TVs suppresses melatonin. | Turn off devices at least an hour before bed, or use â€œnightâ€‘modeâ€ settings. |\n",
      "| **Watch what you eat and drink** | Heavy meals, caffeine, and alcohol can disrupt sleep stages. | Finish eating 2â€“3â€¯hours before bed, avoid caffeine after noon, and limit alcohol to a small glass if you drink. |\n",
      "| **Get regular, moderate exercise** | Physical activity promotes deeper sleep, but exercising too close to bedtime can be stimulating. | Aim for at least 150â€¯minutes of moderate activity per week, finishing at least 3â€¯hours before sleep. |\n",
      "| **Manage stress and unwind mentally** | Chronic stress keeps the nervous system in a heightened state, making it hard to relax. | Try journaling, progressive muscle relaxation, or a short guided meditation before bed. |\n",
      "| **Use the bedroom only for sleep and intimacy** | Associating the room with wakeful activities can weaken the sleep cue. | Keep work, TV, and other stimulating activities out of the bedroom. |\n",
      "| **Consider a short nap if needed** | A brief nap (â‰¤20â€¯minutes) can boost alertness without interfering with nighttime sleep. | Nap early in the afternoon; avoid longer or lateâ€‘day naps. |\n",
      "\n",
      "**Quick reference from the knowledge base**\n",
      "\n",
      "- Adults need **7â€“9â€¯hours** of sleep per night, and sleep cycles last about 90â€¯minutes (Sourceâ€¯2).  \n",
      "- Regular exercise, adequate sleep, a balanced diet, and stress management are key pillars of overall wellness (Sourceâ€¯2).  \n",
      "\n",
      "---\n",
      "\n",
      "### Putting it together\n",
      "\n",
      "1. **Plan your sleep window**: 10â€¯pmâ€“6â€¯am (example).  \n",
      "2. **Windâ€‘down routine**: 9:30â€¯pm â€“ dim lights, read, stretch.  \n",
      "3. **Bedroom environment**: 60â€“67â€¯Â°F, blackout curtains, earplugs.  \n",
      "4. **Exercise**: 30â€¯min brisk walk on most days, finish by 7â€¯pm.  \n",
      "5. **Nutrition**: Light dinner by 7â€¯pm, no caffeine after 2â€¯pm.  \n",
      "6. **Stress**: 10â€‘minute breathing exercise at 9:45â€¯pm.  \n",
      "\n",
      "Give yourself a week to try these changes. If you still struggle, consider keeping a sleep diary (note bedtime, wake time, perceived quality) and share it with a healthcare provider.  \n",
      "\n",
      "**Youâ€™ve got this!** Small, consistent adjustments can lead to big improvements in sleep quality and overall wellâ€‘being. If you have any specific concerns (e.g., insomnia, snoring, restless legs), let me know and we can dive deeper.\n"
     ]
    }
   ],
   "source": [
    "# Test the RAG agent\n",
    "print(\"Testing Agentic RAG (with local models):\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "response = rag_agent.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"What are some tips for better sleep?\")]\n",
    "})\n",
    "\n",
    "print(\"\\nFinal Response:\")\n",
    "print(\"=\" * 50)\n",
    "print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cell-48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with complex query:\n",
      "==================================================\n",
      "\n",
      "Final Response:\n",
      "==================================================\n",
      "Iâ€™m sorry youâ€™re feeling so stressed and having trouble sleeping. Below are some evidenceâ€‘based strategies that can help you calm your mind, improve sleep quality, and manage stress. Iâ€™ve pulled these from the wellness knowledge base to give you the most reliable guidance.\n",
      "\n",
      "---\n",
      "\n",
      "## 1. Quickâ€‘Start Stressâ€‘Reduction Techniques\n",
      "\n",
      "| Technique | How it Helps | Practical Tips |\n",
      "|-----------|--------------|----------------|\n",
      "| **Deepâ€‘breathing / diaphragmatic breathing** | Activates the parasympathetic nervous system, lowering heart rate and cortisol. | 4â€‘7â€‘8 method: inhale 4â€¯s, hold 7â€¯s, exhale 8â€¯s. Do 3â€“5 cycles before bed. |\n",
      "| **Progressive muscle relaxation** | Releases muscle tension that often builds up with stress. | Tense each muscle group for 5â€¯s, then release for 15â€¯s. Work from toes to head. |\n",
      "| **Mindfulness or guided imagery** | Shifts focus away from racing thoughts. | Use a 5â€‘minute guided meditation app (e.g., Insight Timer, Calm). |\n",
      "| **Limit screen time 1â€¯h before bed** | Blue light suppresses melatonin. | Replace with a book, gentle stretching, or a warm shower. |\n",
      "\n",
      "> *Source: Sleep hygiene and stress management guidelines in the wellness knowledge base.*\n",
      "\n",
      "---\n",
      "\n",
      "## 2. Sleepâ€‘Friendly Environment\n",
      "\n",
      "| Element | Why it matters | Quick Fix |\n",
      "|---------|----------------|-----------|\n",
      "| **Consistent bedtime & wake time** | Regulates circadian rhythm. | Aim for the same 7â€“9â€¯h window every day, even weekends. |\n",
      "| **Cool, dark room** | Promotes deeper sleep stages. | Use blackout curtains, a fan, or a whiteâ€‘noise machine. |\n",
      "| **Comfortable mattress & pillows** | Reduces physical discomfort that can wake you. | Replace if you feel aches or stiffness. |\n",
      "| **Limit caffeine & alcohol** | Both can fragment sleep. | Avoid caffeine after 2â€¯pm; limit alcohol to 1â€“2 drinks at most. |\n",
      "\n",
      "> *Source: Sleep cycle and recommended duration information.*\n",
      "\n",
      "---\n",
      "\n",
      "## 3. Lifestyle Tweaks That Reduce Stress & Improve Sleep\n",
      "\n",
      "| Habit | Impact | How to Start |\n",
      "|-------|--------|--------------|\n",
      "| **Regular moderate exercise** | Enhances sleep quality and lowers cortisol. | 30â€¯min brisk walk or light yoga 3â€“4â€¯days/week. |\n",
      "| **Balanced nutrition** | Stable blood sugar keeps you from nighttime awakenings. | Include protein, healthy fats, and complex carbs at dinner. |\n",
      "| **Hydration** | Dehydration can cause nighttime awakenings. | Aim for 1.5â€“2â€¯L/day, but reduce fluids 2â€¯h before bed. |\n",
      "| **Journaling** | Offloads worries before sleep. | Write 5â€“10 minutes of thoughts or gratitude. |\n",
      "\n",
      "> *Source: Immuneâ€‘boosting strategies and general wellness tips.*\n",
      "\n",
      "---\n",
      "\n",
      "## 4. If 6â€¯Hours a Night Is All You Can Get\n",
      "\n",
      "You mentioned sleeping **6â€¯hours per night for a week**. Letâ€™s calculate the total:\n",
      "\n",
      "\\[\n",
      "6 \\text{ hours/night} \\times 7 \\text{ nights} = 42 \\text{ hours}\n",
      "\\]\n",
      "\n",
      "So youâ€™ll have accumulated **42 hours of sleep** over that week. While thatâ€™s a decent amount of total sleep, itâ€™s still below the 7â€“9â€¯hour recommendation for adults. If possible, try to add an extra 30â€“60â€¯minutes each night or take a short nap (20â€“30â€¯min) during the day to help catch up.\n",
      "\n",
      "---\n",
      "\n",
      "## 5. A Gentle Plan for the Next 3 Days\n",
      "\n",
      "1. **Day 1 â€“ Bedtime Routine**  \n",
      "   - 9:00â€¯pm: Light stretching + 4â€‘7â€‘8 breathing.  \n",
      "   - 9:30â€¯pm: Turn off screens, dim lights, read a book.  \n",
      "   - 10:00â€¯pm: Sleep.\n",
      "\n",
      "2. **Day 2 â€“ Exercise & Nutrition**  \n",
      "   - 7:00â€¯am: 30â€‘min walk.  \n",
      "   - 7:30â€¯pm: Dinner with protein + veggies + complex carb.  \n",
      "   - 10:00â€¯pm: Sleep.\n",
      "\n",
      "3. **Day 3 â€“ Mindfulness & Journaling**  \n",
      "   - 8:30â€¯pm: 5â€‘minute guided meditation.  \n",
      "   - 9:00â€¯pm: Write 3 things youâ€™re grateful for.  \n",
      "   - 10:00â€¯pm: Sleep.\n",
      "\n",
      "Feel free to adjust the times to fit your schedule. The key is consistency and giving your body a predictable rhythm.\n",
      "\n",
      "---\n",
      "\n",
      "### Youâ€™re Not Alone\n",
      "\n",
      "Stress and sleep issues are common, and small, consistent changes can make a big difference. If you find that your sleep or stress levels donâ€™t improve after a few weeks, consider speaking with a healthcare professional or a sleep specialist. They can help rule out underlying conditions and tailor a plan just for you.\n",
      "\n",
      "Take care, and remember that each small step is progress. ðŸŒ±\n"
     ]
    }
   ],
   "source": [
    "# Test with a complex query requiring both RAG and calculation\n",
    "print(\"Testing with complex query:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "response = rag_agent.invoke({\n",
    "    \"messages\": [HumanMessage(\n",
    "        content=\"I'm stressed and sleeping poorly. What should I do? Also, if I sleep 6 hours a night for a week, how many total hours is that?\"\n",
    "    )]\n",
    "})\n",
    "\n",
    "print(\"\\nFinal Response:\")\n",
    "print(\"=\" * 50)\n",
    "print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cell-49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing agent decision-making (should NOT use RAG):\n",
      "==================================================\n",
      "\n",
      "Final Response:\n",
      "125â€¯Ã—â€¯8â€¯=â€¯**1,000**.\n"
     ]
    }
   ],
   "source": [
    "# Test that the agent knows when NOT to use RAG\n",
    "print(\"Testing agent decision-making (should NOT use RAG):\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "response = rag_agent.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"What is 125 * 8?\")]\n",
    "})\n",
    "\n",
    "print(\"\\nFinal Response:\")\n",
    "print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-52",
   "metadata": {},
   "source": [
    "---\n",
    "## â“ Question #3:\n",
    "\n",
    "Compare the experience of building an agent from scratch with LangGraph versus using `create_agent` from Session 3. What are the trade-offs between control and convenience? When would you choose one approach over the other?\n",
    "\n",
    "##### Answer:\n",
    "LangGraph from scratch gives full control over the agent loop, state, and routing, but requires more code and design effort.\n",
    "create_agent provides a ready-made ReAct loop with built-in tool calling and stopping logic, so itâ€™s much faster to set up but less customizable.\n",
    "Use create_agent for quick prototypes and simple RAG/tool agents.\n",
    "Use LangGraph when you need production-grade control, branching, retries, or multi-step workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-53",
   "metadata": {},
   "source": [
    "## â“ Question #4:\n",
    "\n",
    "We used local models (gpt-oss:20b and embeddinggemma) instead of cloud APIs. What are the advantages and disadvantages of this approach? \n",
    "\n",
    "##### Answer:\n",
    "Using local models gives privacy, no data leaves your system, and no per-call cost, but requires more hardware and setup.\n",
    "They offer lower latency and offline use, but may be slower or less capable than top cloud models.\n",
    "Cloud APIs scale easily and stay state-of-the-art, but cost money and send data outside your environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-54",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸ—ï¸ Activity #2: Extend the Agent with Memory\n",
    "\n",
    "LangGraph supports **checkpointing** which enables conversation memory across invocations.\n",
    "\n",
    "Your task: Add memory to the RAG agent so it can:\n",
    "1. Remember previous questions in the conversation\n",
    "2. Reference past context when answering new questions\n",
    "3. Build on previous answers\n",
    "\n",
    "Hint: Use `MemorySaver` from `langgraph.checkpoint.memory` and pass a `thread_id` in the config.\n",
    "\n",
    "**ðŸ“š Documentation:**\n",
    "- [LangGraph Persistence & Memory](https://langchain-ai.github.io/langgraph/concepts/persistence/)\n",
    "- [How to add memory to your graph](https://langchain-ai.github.io/langgraph/how-tos/persistence/)\n",
    "- [MemorySaver Reference](https://langchain-ai.github.io/langgraph/reference/checkpoints/#langgraph.checkpoint.memory.MemorySaver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-55",
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# Create memory\n",
    "memory = MemorySaver()\n",
    "\n",
    "# Compile workflow with memory\n",
    "rag_agent_with_memory = rag_workflow.compile(checkpointer=memory)\n",
    "\n",
    "# Run with persistent thread\n",
    "config = {\"configurable\": {\"thread_id\": \"conversation-1\"}}\n",
    "\n",
    "rag_agent_with_memory.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"What is 25 * 48?\")]},\n",
    "    config=config\n",
    ")\n",
    "\n",
    "rag_agent_with_memory.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"Now add 10 to the previous result.\")]},\n",
    "    config=config\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test your memory-enabled agent with a multi-turn conversation\n",
    "# Test your memory-enabled agent with a multi-turn conversation\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"conversation-1\"}}\n",
    "\n",
    "rag_agent_with_memory.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"What is 25 * 48?\")]},\n",
    "    config=config\n",
    ")\n",
    "\n",
    "rag_agent_with_memory.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"Use the previous answer and add 10.\")]},\n",
    "    config=config\n",
    ")\n",
    "\n",
    "rag_agent_with_memory.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"Now multiply that result by 2.\")]},\n",
    "    config=config\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-57",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "In this session, we:\n",
    "\n",
    "1. **Built agents from scratch** using LangGraph's low-level primitives (StateGraph, nodes, edges)\n",
    "2. **Used local open-source models** with Ollama (gpt-oss:20b + embeddinggemma)\n",
    "3. **Transitioned to LangChain** for document loading and text splitting\n",
    "4. **Created an Agentic RAG system** that intelligently decides when to retrieve information\n",
    "\n",
    "### Key Takeaways:\n",
    "\n",
    "- **StateGraph** gives you full control over agent architecture\n",
    "- **Conditional edges** enable dynamic routing based on LLM decisions\n",
    "- **Local models** provide privacy and cost savings, with trade-offs in performance\n",
    "- **LangSmith** provides crucial visibility regardless of where your models run\n",
    "\n",
    "### What's Next?\n",
    "\n",
    "Now that you understand the fundamentals, you can:\n",
    "- Add more sophisticated routing logic\n",
    "- Implement human-in-the-loop patterns\n",
    "- Build multi-agent systems\n",
    "- Deploy to production with LangGraph Platform\n",
    "\n",
    "**ðŸ“š Further Reading:**\n",
    "- [LangGraph How-To Guides](https://langchain-ai.github.io/langgraph/how-tos/)\n",
    "- [Human-in-the-Loop Patterns](https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/)\n",
    "- [Multi-Agent Architectures](https://langchain-ai.github.io/langgraph/concepts/multi_agent/)\n",
    "- [LangGraph Platform](https://langchain-ai.github.io/langgraph/concepts/langgraph_platform/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
